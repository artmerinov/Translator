{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split\n",
    "from datasets import load_dataset\n",
    "\n",
    "from utils import Config\n",
    "from tokenizer import create_tokenizer, load_tokenizer\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DATASOURCE': 'opus_books',\n",
       " 'LANG_SRC': 'ru',\n",
       " 'LANG_TGT': 'it',\n",
       " 'PATH_TO_MODEL_WEIGHTS': 'weights',\n",
       " 'PATH_TO_EXPERIMENTS': 'runs',\n",
       " 'PATH_TO_TOKENIZERS': 'tokenizers',\n",
       " 'TR_FRAC': 0.95,\n",
       " 'MAX_LEN': 250,\n",
       " 'BATCH_SIZE': 32,\n",
       " 'NUM_EPOCHS': 10,\n",
       " 'EMBED_SIZE': 512,\n",
       " 'HIDDEN_SIZE': 2048,\n",
       " 'DROPOUT': 0.1,\n",
       " 'HEADS': 8,\n",
       " 'LAYERS': 6}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = Config('config.yaml')\n",
    "config.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'it': 'La seduta doveva durare fino alle due, senza interruzione; alle due, intervallo e colazione.',\n",
       "  'ru': 'До двух часов занятия должны были идти не прерываясь, а в два часа -- перерыв и завтрак.'},\n",
       " {'it': 'Non erano ancora le due quando la grande porta a vetri dell’aula si aprì improvvisamente e qualcuno entrò.',\n",
       "  'ru': 'Еще не было двух часов, когда большие стеклянные двери залы присутствия вдруг отворились, и кто-то вошел.'},\n",
       " {'it': 'Tutti i membri ritratti sotto il ritratto dell’imperatore e al di là dello specchio a tre facce, lieti della distrazione, si voltarono a guardare verso la porta; ma l’usciere che stava all’ingresso respinse subito colui che s’era infilato e richiuse la porta a vetri.',\n",
       "  'ru': 'Все члены из-под портрета и из-за зерцала, обрадовавшись развлечению, оглянулись на дверь; но сторож, стоявший у двери, тотчас же изгнал вошедшего и затворил за ним стеклянную дверь.'},\n",
       " {'it': 'Quando tutto il rapporto fu letto, Stepan Arkad’ic si alzò stiracchiandosi e, pagando il proprio tributo al liberalismo dell’epoca, tirò fuori, ancora nell’aula, una sigaretta, e si avviò nel suo ufficio.',\n",
       "  'ru': 'Когда дело было прочтено, Степан Аркадьич встал, потянувшись, и, отдавая дань либеральности времени, в присутствии достал папироску и пошел в свой кабинет.'},\n",
       " {'it': 'Due colleghi, il vecchio funzionario Nikitin e il gentiluomo di camera Grinevic, uscirono con lui.',\n",
       "  'ru': 'Два товарища его, старый служака Никитин и камер-юнкер Гриневич, вышли с ним.'}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_raw = load_dataset(\n",
    "    path=config.DATASOURCE, \n",
    "    name=f\"{config.LANG_TGT}-{config.LANG_SRC}\", # ru -> it\n",
    "    split=\"train\"\n",
    ")\n",
    "data_raw['translation'][300:305]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', ',', 'как', 'у', 'тебя', 'дела', '?']\n",
      "['[UNK]', ',', 'come', 'va', '?']\n"
     ]
    }
   ],
   "source": [
    "src_tokenizer = create_tokenizer(dataset=data_raw, config=config, lang=config.LANG_SRC)\n",
    "tgt_tokenizer = create_tokenizer(dataset=data_raw, config=config, lang=config.LANG_TGT)\n",
    "\n",
    "output = src_tokenizer.encode(\"Привет, как у тебя дела?\")\n",
    "print(output.tokens)\n",
    "\n",
    "output = tgt_tokenizer.encode(\"Ciao, come va?\")\n",
    "print(output.tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16115, 1791)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr_size = int(0.9 * len(data_raw))\n",
    "va_size = len(data_raw) - tr_size\n",
    "tr_data_raw, va_data_raw = random_split(data_raw, [tr_size, va_size])\n",
    "len(tr_data_raw), len(va_data_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source (ru) sentence: 187\n",
      "Max length of target (it) sentence: 220\n"
     ]
    }
   ],
   "source": [
    "#  Find the maximum length of each sentence in the source and target sentence\n",
    "max_len_src = 0\n",
    "max_len_tgt = 0\n",
    "\n",
    "for item in data_raw:\n",
    "    src_ids = src_tokenizer.encode(item[\"translation\"][config.LANG_SRC]).ids\n",
    "    tgt_ids = tgt_tokenizer.encode(item[\"translation\"][config.LANG_TGT]).ids\n",
    "    max_len_src = max(max_len_src, len(src_ids))\n",
    "    max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
    "\n",
    "print(f\"Max length of source ({config.LANG_SRC}) sentence: {max_len_src}\")\n",
    "print(f\"Max length of target ({config.LANG_TGT}) sentence: {max_len_tgt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer_translator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
